<!doctype html><html class="not-ready lg:text-base" style=--bg:#faf8f1 lang=zh><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Sparse storage scheme used in MLIR - sh1marin's blog</title><meta name=theme-color><meta name=description content="在 MLIR 里，sparse compiler 会更根据 sparse tensor encoding 的属性，调整 tensor 的存储方式。 SparseTensor Dialect 里提供了 coordinates/values/positions operations， 这三个 operations 有点类似于 bufferizatio"><meta name=author content="sh1marin"><link rel="preload stylesheet" as=style href=https://blog.sh1mar.in/main.min.css><script defer src=https://blog.sh1mar.in/highlight.min.js onload=hljs.initHighlightingOnLoad()></script>
<link rel=preload as=image href=https://blog.sh1mar.in/theme.png><link rel=preload as=image href=https://blog.sh1mar.in/github.svg><link rel=preload as=image href=https://blog.sh1mar.in/rss.svg><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css integrity=sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<link rel=icon href=https://blog.sh1mar.in/favicon.ico><link rel=apple-touch-icon href=https://blog.sh1mar.in/apple-touch-icon.png><meta name=generator content="Hugo 0.112.3"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css integrity=sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><meta property="og:title" content="Sparse storage scheme used in MLIR"><meta property="og:description" content="在 MLIR 里，sparse compiler 会更根据 sparse tensor encoding 的属性，调整 tensor 的存储方式。 SparseTensor Dialect 里提供了 coordinates/values/positions operations， 这三个 operations 有点类似于 bufferizatio"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.sh1mar.in/post/mlir/sparse-storage-scheme/"><meta property="article:section" content="post"><meta property="article:published_time" content="2023-07-03T00:00:00+08:00"><meta property="article:modified_time" content="2023-07-03T00:00:00+08:00"><meta itemprop=name content="Sparse storage scheme used in MLIR"><meta itemprop=description content="在 MLIR 里，sparse compiler 会更根据 sparse tensor encoding 的属性，调整 tensor 的存储方式。 SparseTensor Dialect 里提供了 coordinates/values/positions operations， 这三个 operations 有点类似于 bufferizatio"><meta itemprop=datePublished content="2023-07-03T00:00:00+08:00"><meta itemprop=dateModified content="2023-07-03T00:00:00+08:00"><meta itemprop=wordCount content="1290"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Sparse storage scheme used in MLIR"><meta name=twitter:description content="在 MLIR 里，sparse compiler 会更根据 sparse tensor encoding 的属性，调整 tensor 的存储方式。 SparseTensor Dialect 里提供了 coordinates/values/positions operations， 这三个 operations 有点类似于 bufferizatio"></head><body class="text-black duration-200 ease-out dark:text-white"><header class="mx-auto flex h-[4.5rem] max-w-3xl px-8 lg:justify-center"><div class="relative z-50 mr-auto flex items-center"><a class="-translate-x-[1px] -translate-y-[1px] text-2xl font-semibold" href=https://blog.sh1mar.in>sh1marin's blog</a><div class="btn-dark text-[0] ml-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.svg)_left_center/cover_no-repeat] dark:invert dark:[background-position:right]" role=button aria-label=Dark></div></div><div class="btn-menu relative z-50 -mr-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden" role=button aria-label=Menu></div><script>const htmlClass=document.documentElement.classList;setTimeout(()=>{htmlClass.remove("not-ready")},10);const btnMenu=document.querySelector(".btn-menu");btnMenu.addEventListener("click",()=>{htmlClass.toggle("open")});const metaTheme=document.querySelector('meta[name="theme-color"]'),lightBg="#faf8f1".replace(/"/g,""),setDark=e=>{metaTheme.setAttribute("content",e?"#000":lightBg),htmlClass[e?"add":"remove"]("dark"),localStorage.setItem("dark",e)},darkScheme=window.matchMedia("(prefers-color-scheme: dark)");if(htmlClass.contains("dark"))setDark(!0);else{const e=localStorage.getItem("dark");setDark(e?e==="true":darkScheme.matches)}darkScheme.addEventListener("change",e=>{setDark(e.matches)});const btnDark=document.querySelector(".btn-dark");btnDark.addEventListener("click",()=>{setDark(localStorage.getItem("dark")!=="true")})</script><div class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"><nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6"><a class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal" href=/about/>About</a></nav><nav class="mt-12 flex justify-center space-x-10 dark:invert lg:ml-12 lg:mt-0 lg:items-center lg:space-x-6"><a class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./github.svg) href=https://github.com/Avimitin target=_blank rel=me>github</a>
<a class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6" style=--url:url(./rss.svg) href=https://blog.sh1mar.in/index.xml target=_blank rel=alternate>rss</a></nav></div></header><main class="prose prose-neutral relative mx-auto min-h-[calc(100%-9rem)] max-w-3xl px-8 pb-16 pt-12 dark:prose-invert"><article><header class=mb-16><h1 class="!my-0 pb-2.5">Sparse storage scheme used in MLIR</h1><div class="text-sm antialiased opacity-60"><time>Jul 3, 2023</time>
<span class=mx-1>&#183;</span>
<span>sh1marin</span></div></header><section><p>在 MLIR 里，sparse compiler 会更根据 sparse tensor encoding 的属性，调整 tensor 的存储方式。
SparseTensor Dialect 里提供了 <code>coordinates</code>/<code>values</code>/<code>positions</code> <em>operation</em>s，
这三个 <em>operation</em>s 有点类似于 <code>bufferization.to_memref</code>，将高抽象的 tensor 降至具体的缓存操作，
让我们得以一窥 sparse tensor 的存储结构。</p><p>利用这三个操作，我们可以很清晰的看到 MLIR 的 Sparse Compiler 具体对 tensor 使用的存储方式。
在开始介绍之前，我先提前写一个等会可以用来辅助的伪代码， MLIR 操作 <code>dump</code>。</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-mlir data-lang=mlir><span style=display:flex><span><span style=color:#fabd2f>func</span>.<span style=color:#fabd2f>func</span> <span style=color:#fabd2f>@dump</span>(%arg: <span style=color:#fabd2f>tensor</span>&lt;*xf32, #Attr&gt;) {
</span></span><span style=display:flex><span>  <span style=color:#928374;font-style:italic>// Iterate all the dimension of the tensor
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic></span>  affine.for %lvl = <span style=color:#d3869b>0</span> to L {
</span></span><span style=display:flex><span>    <span style=color:#928374;font-style:italic>// Print pointers
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic></span>    %p = sparse_tensor.positions %arg { <span style=color:#fb4934>level =</span> %lvl : <span style=color:#fe8019>index</span> }
</span></span><span style=display:flex><span>          : <span style=color:#fabd2f>tensor</span>&lt;*xf32, #Attr&gt; to <span style=color:#fabd2f>memref</span>&lt;<span style=color:#d3869b>?x</span><span style=color:#fe8019>index</span>&gt;
</span></span><span style=display:flex><span>    <span style=color:#928374;font-style:italic>// Convert operation...
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic></span>    <span style=color:#fabd2f>vector</span>.print %p : ...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#928374;font-style:italic>// Print indices (coordinate)
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic></span>    %c = sparse_tensor.coordinates %arg { <span style=color:#fb4934>level =</span> %lvl : <span style=color:#fe8019>index</span> }
</span></span><span style=display:flex><span>          : <span style=color:#fabd2f>tensor</span>&lt;*xf32, #Attr&gt; to <span style=color:#fabd2f>memref</span>&lt;<span style=color:#d3869b>?x</span><span style=color:#fe8019>index</span>&gt;
</span></span><span style=display:flex><span>    <span style=color:#928374;font-style:italic>// ...
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic></span>    <span style=color:#fabd2f>vector</span>.print %c : ...
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#928374;font-style:italic>// Print values (non-zero entries)
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic></span>  %v = sparse_tensor.values %arg : <span style=color:#fabd2f>tensor</span>&lt;*xf32, #Attr&gt; to <span style=color:#fabd2f>memref</span>&lt;<span style=color:#d3869b>?x</span><span style=color:#fe8019>f32</span>&gt;
</span></span><span style=display:flex><span>  <span style=color:#928374;font-style:italic>// ...
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic></span>  <span style=color:#fabd2f>vector</span>.print %v1 : ...
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#fabd2f>return</span>
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>上面的这个 <code>@dump</code> 操作中，我省略了很多类型转换的操作，
以及使用了 <code>affine.for</code> 来遍历 tensor 的每一个 dimension。
但实际上 <code>level</code> 只接受静态常数，在编译期会用来检查访问是否超越 tensor rank 。</p><p>在一个 tensor 内有 0 到指定级别的 dimensions，在指定 tensor 的 sparse attribute 时，
需要用 <code>lvlType</code> （旧版本是 <code>dimLevelType</code> ）对不同的 dimension 注释稀疏程度。
对于给定 <code>compressed</code> 级别的，Sparse Compiler 会对这一层的 tensor 使用如下的存储方式：</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-mlir data-lang=mlir><span style=display:flex><span>#SparseVector = #sparse_tensor.encoding&lt;{
</span></span><span style=display:flex><span>  <span style=color:#fb4934>lvlType =</span> [ <span style=color:#b8bb26>&#34;compressed&#34;</span> ]
</span></span><span style=display:flex><span>}&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// Create a sparse vector with value 1.1,2.2,3.3,4.4 at v0[3], v0[6], v0[9], v0[12]
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic></span>%v0 = arith.<span style=color:#fabd2f>constant</span> sparse&lt;
</span></span><span style=display:flex><span>  [ [<span style=color:#d3869b>3</span>], [<span style=color:#d3869b>6</span>], [<span style=color:#d3869b>9</span>], [<span style=color:#d3869b>12</span>] ],
</span></span><span style=display:flex><span>  [ <span style=color:#d3869b>1.1</span>, <span style=color:#d3869b>2.2</span>, <span style=color:#d3869b>3.3</span>, <span style=color:#d3869b>4.4</span> ]
</span></span><span style=display:flex><span>&gt; : <span style=color:#fabd2f>tensor</span>&lt;<span style=color:#d3869b>16x</span><span style=color:#fe8019>f32</span>&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>%sv0 = sparse_tensor.convert %v0 : <span style=color:#fabd2f>tensor</span>&lt;<span style=color:#d3869b>16x</span><span style=color:#fe8019>f32</span>&gt; to <span style=color:#fabd2f>tensor</span>&lt;<span style=color:#d3869b>16x</span><span style=color:#fe8019>f32</span>, #SparseVector&gt;
</span></span><span style=display:flex><span>call <span style=color:#fabd2f>@dump</span>(%sv0)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-json data-lang=json><span style=display:flex><span>pointers[<span style=color:#d3869b>0</span>]: [ <span style=color:#d3869b>0</span>, <span style=color:#d3869b>4</span> ]
</span></span><span style=display:flex><span>indices[<span style=color:#d3869b>0</span>]: [ <span style=color:#d3869b>3</span>, <span style=color:#d3869b>6</span>, <span style=color:#d3869b>9</span>, <span style=color:#d3869b>12</span> ]
</span></span><span style=display:flex><span>values: [ <span style=color:#d3869b>1.1</span>, <span style=color:#d3869b>2.2</span>, <span style=color:#d3869b>3.3</span>, <span style=color:#d3869b>4.4</span> ]
</span></span></code></pre></div><p>在上面的例子里，因为给定了一个 rank 只有 1 的 tensor，所以 <code>pointers</code> 和 <code>indices</code>
都只是一个仅有一个元素的数组。values 则永远是一个一维的数组。
<code>pointers</code> 数组用来存放访问的 “范围”。
比如上述的例子，<code>[0, 4]</code> 用来 <code>indices</code> 和 <code>values</code> 在访问 tensor dimension 1 时的取值。
使用 sparse vector 做例子会有些令人迷惑：“看起来我不需要多这么一个 pointers 存储我就可以知道我的访问便捷呀？”
所以下面这里再给一个 8 维度，使用 Compressed Sparse Row 存储的例子：</p><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-mlir data-lang=mlir><span style=display:flex><span><span style=color:#928374;font-style:italic>// &#34;dense&#34; for first level, &#34;compressed&#34; for the second level
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic></span>#CSR = #sparse_tensor.encoding&lt;{
</span></span><span style=display:flex><span>  <span style=color:#fb4934>lvlType =</span> [ <span style=color:#b8bb26>&#34;dense&#34;</span>, <span style=color:#b8bb26>&#34;compressed&#34;</span> ]
</span></span><span style=display:flex><span>}&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// Create a sparse matrix %m
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// +-----+-----+-----+-----+-----+-----+-----+-----+
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// + 0.0 | 1.1 | 0.0 | 0.0 | 2.2 | 0.0 | 0.0 | 0.0 |
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// +-----+-----+-----+-----+-----+-----+-----+-----+
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// + 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// +-----+-----+-----+-----+-----+-----+-----+-----+
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// + 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// +-----+-----+-----+-----+-----+-----+-----+-----+
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// + 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// +-----+-----+-----+-----+-----+-----+-----+-----+
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// + 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// +-----+-----+-----+-----+-----+-----+-----+-----+
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// + 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// +-----+-----+-----+-----+-----+-----+-----+-----+
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// + 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// +-----+-----+-----+-----+-----+-----+-----+-----+
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// + 0.0 | 0.0 | 3.3 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// +-----+-----+-----+-----+-----+-----+-----+-----+
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>//
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// with value 1.1 in m[0, 1], 2.2 in m[0, 4], 3.3 in m[7, 2]
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic>// with rank 2, shape 8x8, dtype f32
</span></span></span><span style=display:flex><span><span style=color:#928374;font-style:italic></span>%m = arith.<span style=color:#fabd2f>constant</span> sparse&lt;
</span></span><span style=display:flex><span>  [ [<span style=color:#d3869b>0</span>, <span style=color:#d3869b>1</span>], [<span style=color:#d3869b>0</span>, <span style=color:#d3869b>4</span>], [<span style=color:#d3869b>7</span>, <span style=color:#d3869b>2</span>] ],
</span></span><span style=display:flex><span>  [  <span style=color:#d3869b>1.1</span>,    <span style=color:#d3869b>2.2</span>,    <span style=color:#d3869b>3.3</span>  ]
</span></span><span style=display:flex><span>&gt; : <span style=color:#fabd2f>tensor</span>&lt;<span style=color:#d3869b>8x8x</span><span style=color:#fe8019>f32</span>&gt;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>%sm = sparse_tensor.convert %m : <span style=color:#fabd2f>tensor</span>&lt;<span style=color:#d3869b>8x8x</span><span style=color:#fe8019>f32</span>&gt; to <span style=color:#fabd2f>tensor</span>&lt;<span style=color:#d3869b>8x8x</span><span style=color:#fe8019>f32</span>, #CSR&gt;
</span></span><span style=display:flex><span>call <span style=color:#fabd2f>@dump</span>(%sm) : (<span style=color:#fabd2f>tensor</span>&lt;<span style=color:#d3869b>8x8x</span><span style=color:#fe8019>f32</span>, #CSR&gt;) -&gt; ()
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#ebdbb2;background-color:#282828;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-json data-lang=json><span style=display:flex><span>d<span style=color:#d3869b>1</span>: dense
</span></span><span style=display:flex><span>d<span style=color:#d3869b>2</span>:
</span></span><span style=display:flex><span>    pointers[<span style=color:#d3869b>1</span>]: [ <span style=color:#d3869b>0</span>, <span style=color:#d3869b>2</span>, <span style=color:#d3869b>2</span>, <span style=color:#d3869b>2</span>, <span style=color:#d3869b>2</span>, <span style=color:#d3869b>2</span>, <span style=color:#d3869b>2</span>, <span style=color:#d3869b>3</span>, <span style=color:#d3869b>3</span> ] # Length = <span style=color:#d3869b>9</span>
</span></span><span style=display:flex><span>    indices[<span style=color:#d3869b>1</span>]: [ <span style=color:#d3869b>1</span>, <span style=color:#d3869b>4</span>, <span style=color:#d3869b>2</span> ]
</span></span><span style=display:flex><span>    values: [ <span style=color:#d3869b>1.1</span>, <span style=color:#d3869b>2.2</span>, <span style=color:#d3869b>3.3</span> ]
</span></span></code></pre></div><p>使用 CSR 结构的存储，第一层会用 dense 的缓存来存储，第二层才使用特殊的数据结构。
其中 pointers 的含义依旧不变，仍旧是用来指引 indices 和 values 的 range。
抽象总结的来说，对于 \(row i\)，设 <code>pointers[1][i-1]</code> 为 \(start\)，设 <code>pointers[1][i]</code> 为 \(end\)，
则范围 \([start, end)\) 指引了 \(row i\) 上的 indices 和 values 的取值范围。</p><p>举例来讲，假设我目前想访问 \(row 1\) 上的值，则 <code>pointers[1][0]</code>, <code>pointers[1][1]</code> 设置
访问的 range 为 \([0, 2)\)，意味着仅有 <code>indices[1][0..2]</code>，<code>values[0..2]</code> 的值是属于 \(row 1\) 的，
即 <code>[1, 4]</code> 和 <code>[ 1.1, 2.2 ]</code>。而我想访问 \(row 8\) 上的值，则 <code>pointers[1][6], pointers[1][7]</code> 设置
访问的 range 为 \([2, 3)\)，即对应 indices 的值 <code>2</code> 和 values 的值 <code>3.3</code>。
对于一个零值而言，访问其 row 则只能得到非法 range \([n, n)\)，取不到值，则返回零。</p><p>现在再和上面的矩阵对比，我想 <code>pointers</code> 的意义就一目了然了。</p></section><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css integrity=sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js integrity=sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script><nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]"><a class="flex w-1/2 items-center rounded-l-md p-6 pr-3 font-semibold no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]" href=https://blog.sh1mar.in/post/mlir/sparse-vectorization/><span class=mr-1.5>←</span><span>MLIR - Sparse Vectorization</span></a>
<a class="ml-auto flex w-1/2 items-center justify-end rounded-r-md p-6 pl-3 font-semibold no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]" href=https://blog.sh1mar.in/post/nix/bump-vector-llvm/><span>Using latest LLVM in nix</span><span class=ml-1.5>→</span></a></nav></article></main><footer class="opaco mx-auto flex h-[4.5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"><div class=mr-auto>&copy; 2024
<a class=link href=https://blog.sh1mar.in>sh1marin's blog</a></div><a class="link mx-6" href=https://gohugo.io/ rel=noopener target=_blank>Powered by Hugo️️</a>️
<a class=link href=https://github.com/nanxiaobei/hugo-paper rel=noopener target=_blank>✎ Paper</a></footer></body></html>